{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - Comprehensive Guide\n",
    "\n",
    "Learn clustering and dimensionality reduction.\n",
    "\n",
    "## Table of Contents\n",
    "1. [K-Means Clustering](#kmeans)\n",
    "2. [Hierarchical Clustering](#hierarchical)\n",
    "3. [DBSCAN](#dbscan)\n",
    "4. [PCA](#pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_blobs, load_iris\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering <a id='kmeans'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=42)\n",
    "\n",
    "# Apply K-Means\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis')\n",
    "plt.title('True Labels')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='viridis')\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],\n",
    "            s=300, c='red', marker='X', edgecolors='black', label='Centroids')\n",
    "plt.title('K-Means Clustering')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Silhouette score\n",
    "score = silhouette_score(X, y_pred)\n",
    "print(f\"Silhouette Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method\n",
    "inertias = []\n",
    "K_range = range(1, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering <a id='hierarchical'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "X, _ = make_blobs(n_samples=50, centers=3, random_state=42)\n",
    "\n",
    "# Create dendrogram\n",
    "linkage_matrix = linkage(X, method='ward')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(linkage_matrix)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.show()\n",
    "\n",
    "# Apply hierarchical clustering\n",
    "hierarchical = AgglomerativeClustering(n_clusters=3)\n",
    "y_pred = hierarchical.fit_predict(X)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap='viridis')\n",
    "plt.title('Hierarchical Clustering Result')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN <a id='dbscan'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data with noise\n",
    "X, _ = make_blobs(n_samples=300, centers=3, cluster_std=0.5, random_state=42)\n",
    "noise = np.random.rand(50, 2) * 10 - 5\n",
    "X = np.vstack([X, noise])\n",
    "\n",
    "# Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "y_pred = dbscan.fit_predict(X)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "unique_labels = set(y_pred)\n",
    "colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "for label, color in zip(unique_labels, colors):\n",
    "    if label == -1:\n",
    "        color = 'black'\n",
    "    mask = (y_pred == label)\n",
    "    plt.scatter(X[mask, 0], X[mask, 1], c=[color], label=f'Cluster {label}',\n",
    "                alpha=0.7, edgecolors='black' if label == -1 else None)\n",
    "\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Number of clusters: {len(set(y_pred)) - (1 if -1 in y_pred else 0)}\")\n",
    "print(f\"Number of noise points: {list(y_pred).count(-1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (Principal Component Analysis) <a id='pca'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', edgecolors='black')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.title('PCA of Iris Dataset')\n",
    "plt.colorbar(scatter, label='Species')\n",
    "plt.show()\n",
    "\n",
    "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
    "print(\"Total explained variance:\", sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree plot\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_scaled)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(pca_full.explained_variance_ratio_) + 1),\n",
    "         np.cumsum(pca_full.explained_variance_ratio_), 'bo-')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Scree Plot')\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Covered:\n",
    "- K-Means clustering with elbow method\n",
    "- Hierarchical clustering with dendrograms\n",
    "- DBSCAN for density-based clustering\n",
    "- PCA for dimensionality reduction\n",
    "- Evaluation metrics\n",
    "\n",
    "Congratulations on completing the ML Revision course! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
